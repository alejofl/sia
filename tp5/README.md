# Deep Learning - Autoencoders

## Overview

This project is an implementation of a deep learning engine that uses autoencoders to solve three different problems: reduction of dimensionality of 7x5 images of letters, denoising of 7x5 images of letters, and generation of new emojis based on a dataset of eight 20x20 PNG images.

## Features

The engine has the following features:

- **Implementation**: conventional autoencoder, denoising autoencoder, and variational autoencoder.
- **Optimization Algorithms**: Gradient Descent, Momentum, and Adam.
- **Weights Update Methods**: Online, Batch, and Mini-Batch.
- **Activation Functions**: Linear, Logistic, Tanh, and ReLU.
- **Noise Types**: Gaussian and Salt-and-Pepper, for the study of denoising autoencoders.

## How to Run

### Prerequisites

The following libraries are required to run the code:

- Python 3
- Pipenv

You can install the required packages using:

```bash
pipenv install
```

### Running the Engine

To run the engine, execute the following command:

```bash
pipenv run python main.py <config_file> <load_pickle> <dump_pickle>
```

Where `<config_file>` is the path to the configuration file, where all of the parameters for the engine are stored. The configuration file must be a JSON file with the following structure:

```json
{
	"problem": "CONVENTIONAL | DENOISING | VARIATIONAL",
	"problemOptions": {
		"noiseType": "GAUSSIAN | SALT_AND_PEPPER", // Only needed for DENOISING problem
		"noiseThreshold": 0.1, // Only needed for SALT_AND_PEPPER noise type
		"noiseLevel": 0.1 // Only needed for GAUSSIAN noise type
	},
	"hyperparameters": {
		"epsilon": 3e-2,
		"maxEpochs": 10000,
		"optimizer": {
			"type": "GRADIENT_DESCENT | MOMENTUM | ADAM",
			"options": {
				"rate": 1e-2,
				"alpha": 0.9, // Only needed for MOMENTUM type
				"beta1": 0.9, // Only needed for ADAM type
				"beta2": 0.999 // Only needed for ADAM type
			}
		},
		"updater": {
			"type": "ONLINE | BATCH | MINI-BATCH",
			"options": {
				"batchSize": 15 // Only needed for MINI-BATCH type
			}
		}
	},
	"architecture": [
		{
			"neuronQty": 35,
			"activationFunction": {
				"type": "LINEAR | LOGISTIC | TANH | RELU",
				"options": {
					"beta": 0.5 // Only needed for LOGISTIC or TANH type
				}
			}
		}
	],
	"seed": 732
}
```

An example configuration file is provided in the `config` directory.

The `<load_pickle>` and `<dump_pickle>` parameters are optional and are used to load and dump the model from/to a pickle file, respectively.

There's a predefined name each pickle file, depending on the problem type:

* For the CONVENTIONAL problem, the pickle file is named `lettersAE.pickle`.
* For the DENOISING problem, the pickle file is named `lettersDAE.pickle`.
* For the VARIATIONAL problem, the pickle file is named `iconsVAE.pickle`.

### Calculating and Plotting Results

There are a few methods to output the results of the engine, in CSV format. You can edit the `print.py` file and run the following command to generate the CSV files:

```bash
pipenv run python print.py <pickle_file>
```

Where `<pickle_file>` is the path to the pickle file generated by the engine.

To plot the results, you can run the following command:

```bash
pipenv run python plot.py
```
